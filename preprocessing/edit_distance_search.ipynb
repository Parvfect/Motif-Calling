{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24f81990",
   "metadata": {},
   "source": [
    "# Edit distance search\n",
    "Manipulating inference results, creating training and testing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2542dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b9eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\edit_distance_motif_search\\res-loose-chain.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd980c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prediction(edit_motif_search_prediction):\n",
    "\n",
    "    cleaned_prediction = []\n",
    "    for i in edit_motif_search_prediction:\n",
    "        if i == 'fake':\n",
    "            cleaned_prediction.append([])\n",
    "        else:\n",
    "            cleaned_prediction.append([int(i[1])])\n",
    "\n",
    "    return cleaned_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22975d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_edit_dataframe(edit_inference_filename):\n",
    "\n",
    "    with open(edit_inference_filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    motif_predictions = []\n",
    "    orientations = []\n",
    "    read_ids = []\n",
    "    ont_barcode = []\n",
    "\n",
    "    for line in tqdm(lines):\n",
    "        split_line = line.split()\n",
    "        read_id = split_line[0][3:]\n",
    "        orientation = split_line[1]\n",
    "        prediction = split_line[4][8:].split('->')\n",
    "        if not (prediction[0].startswith('f') or prediction[0].startswith('m')):\n",
    "            prediction = prediction[1:]\n",
    "\n",
    "        cleaned_prediction = clean_prediction(prediction)\n",
    "        \n",
    "        motif_predictions.append(cleaned_prediction)\n",
    "        orientations.append(orientation)\n",
    "        read_ids.append(read_id)\n",
    "    \n",
    "    df = pd.DataFrame({\"read_id\": read_ids, \"orientation\": orientations, \"motif_seq\": motif_predictions})\n",
    "    df = df.drop_duplicates(subset=['read_id'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9595b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_edit_dataframe(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dil = pd.read_pickle(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\full_datasets\\diluted_EIC04.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(dil, df, on='read_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f04eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663eb34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['ONT_Barcode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf04c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(os.listdir(basepath)):\n",
    "    df = get_edit_dataframe(os.path.join(basepath, file))\n",
    "    master_df = pd.concat([master_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_pickle(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\01-04run\\edit_medium.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e786bb",
   "metadata": {},
   "source": [
    "## Balancing edit-train df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_functions import get_cleaned_encoded_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.read_csv(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\EIC01-01-1280-T1_encoded.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = get_cleaned_encoded_file(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e026633",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t[['ONT_Barcode', 'HW_Address', 'payload']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d72d472",
   "metadata": {},
   "source": [
    "### Adding edit labels to test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb687709",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_df = pd.read_pickle(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\edit_distance_motif_search\\edit_distance_motif_search.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d34fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a60bd6c",
   "metadata": {},
   "source": [
    "## Extracting a fastq with all the subset reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5370df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.read_pickle(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\full_datasets\\diluted_EIC04.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_read_ids = set(encoded_df['read_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bdd1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_barcodes = ['barcode_external02_internal02', 'barcode_external08_internal01',\n",
    "       'barcode_external05_internal01', 'barcode_external02_internal03',\n",
    "       'barcode_external02_internal05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = encoded_csv.loc[encoded_csv['HW_Address'].isin(filtered_barcodes)].sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d23c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\fastq\\EIC01-01-1280\\FASTQ(pass_fail_logs)\\fail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75940392",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_read_ids = filtered_df['read_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cfa278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO, SeqRecord\n",
    "\n",
    "def parse_biopython(input_fastq):\n",
    "    for record in SeqIO.parse(input_fastq, 'fastq'):\n",
    "        yield record\n",
    "\n",
    "def get_fastq_records(fastq_filepath, master_read_ids):\n",
    "    records = []\n",
    "    for i, record in enumerate(parse_biopython(fastq_filepath)):\n",
    "        if record.id in master_read_ids:\n",
    "            records.append(record)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a4101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a37349",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_read_ids = set(master_read_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(os.listdir(basepath)):\n",
    "    if file.endswith('.fastq'):\n",
    "        records = get_fastq_records(os.path.join(basepath, file), master_read_ids)\n",
    "        master_records.extend(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_read_ids = [str(i.id) for i in master_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679eb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged['read_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(record_read_ids).intersection(set(merged['read_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438996e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [i for i in master_records if i.id in master_read_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3eb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fasta_file(ids, strands, output_filepath):\n",
    "    with open(output_filepath, 'w') as f:\n",
    "        for i, strand in enumerate(strands):\n",
    "            f.write(f\">{ids[i]}\\n\")\n",
    "            f.write(strand + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93545858",
   "metadata": {},
   "outputs": [],
   "source": [
    "strands = [str(i.seq) for i in master_records]\n",
    "ids = [str(i.id) for i in master_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552a5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\fastq\\EIC01-01-1280\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_filepath, f\"fq.fastq\"), \"w\") as output_handle:\n",
    "        SeqIO.write(master_records, output_handle, \"fastq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277e5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting by 10000 reads - since MCED can handle it and outputting files\n",
    "\n",
    "for ind, i in enumerate(range(0, len(master_records), 10000)):\n",
    "    with open(os.path.join(basepath, f\"fq{ind}.fastq\"), \"w\") as output_handle:\n",
    "        SeqIO.write(master_records[i: i + 10000], output_handle, \"fastq\")\n",
    "\n",
    "# This worked! Let's see how long it takes - failed halfway through huh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed1cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_functions import sort_library_motif_transcript\n",
    "\n",
    "t = dil['library_motif'].apply(lambda x: sort_library_motif_transcript(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dfb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922db27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.mebrge(encoded_df, df, on='read_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a94fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c8a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_pickle(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\full_datasets\\master_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b27ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['motif_seq'] = merged_df['edit_search_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cca17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['orientation_x'] = merged_df['orientation_x'].apply(lambda x: 1 if x.startswith('+') else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf26bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "found_arr = []\n",
    "err_arr = []\n",
    "orientation_arr = []\n",
    "total = 0\n",
    "for ind, row in merged_df.iterrows():\n",
    "    edit_seq = row['motif_seq']\n",
    "    payload = row['payload_seq']\n",
    "    orientation = row['orientation_x']\n",
    "\n",
    "    found_, err_ = evaluate_prediction(edit_seq[2:], payload)\n",
    "    found_arr.append(found_)\n",
    "    err_arr.append(err_)\n",
    "    orientation_arr.append(orientation)\n",
    "    total += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame({\n",
    "    \"mf_edit\": found_arr,\n",
    "    \"me_edit\": err_arr,\n",
    "    \"orientation\": orientation_arr\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd479e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = t.loc[t['mf_edit'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961efdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d770aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_values = filtered_df.mean(numeric_only=True)\n",
    "\n",
    "print(\"Mean metrics combined:\")\n",
    "print(mean_values.to_frame(name='Mean').T)\n",
    "print()\n",
    "\n",
    "mean_values = filtered_df.loc[filtered_df['orientation'] == 1].mean(numeric_only=True)\n",
    "print(\"Mean metrics forward\")\n",
    "print(mean_values.to_frame(name='Mean').T)\n",
    "print()\n",
    "\n",
    "mean_values = filtered_df.loc[filtered_df['orientation'] == 0].mean(numeric_only=True)\n",
    "print(\"Mean metrics reverse\")\n",
    "print(mean_values.to_frame(name='Mean').T)\n",
    "print()\n",
    "\n",
    "\n",
    "print(f\"{len(filtered_df)/ len(merged_df) * 100}% of pool\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd94025",
   "metadata": {},
   "source": [
    "### Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa09ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aac865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tallies(tallies, prediction):\n",
    "\n",
    "    for ind, i in enumerate(prediction):\n",
    "        for j in i:\n",
    "            tallies[ind][j-1] += 1\n",
    "\n",
    "    return tallies\n",
    "\n",
    "def evaluate_motif_tallies(motif_tallies, payload_cycles):\n",
    "    correct = 0\n",
    "    errs = 0\n",
    "    for tallies, cycle in zip(motif_tallies, payload_cycles):\n",
    "        sorted_tallies = np.argsort(tallies)[::-1]\n",
    "        top_4 = [i+1 for i in sorted_tallies[:4]]\n",
    "        correct += len(set(top_4).intersection(set(cycle)))\n",
    "        errs += len(set(top_4) - set(cycle))\n",
    "\n",
    "    return correct / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2154fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dil[\"motif_seq\"] =  t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = t['mf_edit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67faf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['mf'] = mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_barcodes = np.arange(2, 81, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1290bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['ONT_Barcode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec96ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_ = merged.loc[merged['ONT_Barcode'].isin(t1_barcodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For barcoded runs\n",
    "\n",
    "edit_predictions_arr = []\n",
    "payloads_arr = []\n",
    "batch_size = 8\n",
    "quality_threshold = 12\n",
    "prob_threshold = 0.85\n",
    "\n",
    "# Testing convergence - add quality filtering..\n",
    "for barcode in tqdm(test_df_['ONT_Barcode'].unique()):\n",
    "    u_cycle = 0\n",
    "    for cycle in tqdm(test_df_['HW_Address'].unique()):\n",
    "        selected_df = test_df_.loc[\n",
    "            (test_df_['ONT_Barcode'] == barcode) &\n",
    "            (test_df_['HW_Address'] == cycle)\n",
    "        ]\n",
    "        read_ids = selected_df['read_id'].tolist()\n",
    "        if len(read_ids) == 0:\n",
    "            continue\n",
    "        payload = selected_df['payload'].tolist()[0]\n",
    "        decoded_predictions = selected_df['motif_seq']\n",
    "        edit_predictions_arr.append([i[2:] for i in decoded_predictions])\n",
    "        \n",
    "        payloads_arr.append(payload)\n",
    "        u_cycle += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For the non barcoded runs\n",
    "\n",
    "search_predictions_arr = []\n",
    "payloads_arr = []\n",
    "batch_size = 8\n",
    "quality_threshold = 12\n",
    "prob_threshold = 0.85\n",
    "\n",
    "\n",
    "for cycle in tqdm(test_df_['HW_Address'].unique()):\n",
    "    selected_df = test_df_.loc[\n",
    "        (test_df['HW_Address'] == cycle) #&\n",
    "        #(test_df['strand'].str.startswith('+')) \n",
    "    ]\n",
    "    read_ids = selected_df['read_id'].tolist()\n",
    "    payload = selected_df['payload'].tolist()[0]\n",
    "    #search_predictions = selected_df['motif_seq'].tolist()\n",
    "    #search_predictions_sorted = [\n",
    "    #    sort_transcript(i) for i in selected_df['motif_seq'].tolist()]\n",
    "    decoded_predictions = [i[2:] for i in selected_df['motif_seq'].tolist()][:150]\n",
    "    \n",
    "    #search_predictions_arr.append(search_predictions_sorted[:len(decoded_predictions)])\n",
    "    search_predictions_arr.append(decoded_predictions)\n",
    "    \n",
    "    payloads_arr.append(payload)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from utils import evaluate_prediction\n",
    "\n",
    "def get_top_4_motifs(tallies: dict):\n",
    "    prediction = []\n",
    "    for i in range(len(tallies)):\n",
    "        elems = heapq.nlargest(4, tallies[i].values())\n",
    "        inds = heapq.nlargest(4, tallies[i].keys(), key = lambda x: tallies[i][x])\n",
    "        prediction.append([k for j, k in zip(elems, inds) if j > 0 ])\n",
    "\n",
    "    return prediction\n",
    "\n",
    "#payloads_arr = [eval(i) for i in payloads_arr]\n",
    "\n",
    "\n",
    "search_accs_arr = []\n",
    "caller_accs_arr = []\n",
    "edit_accs_arr = []\n",
    "\n",
    "\n",
    "### Comment out when non-barcoded\n",
    "caller_predictions_arr = edit_predictions_arr\n",
    "search_predictions_arr = edit_predictions_arr\n",
    "\n",
    "for search_prediction, caller_prediction, edit_prediction, payload in zip(\n",
    "    search_predictions_arr, caller_predictions_arr, edit_predictions_arr, payloads_arr):\n",
    "\n",
    "    n_reads = 0\n",
    "    motif_tallies_caller = [{i: 0 for i in range(1, 9)} for i in range(8)]\n",
    "    motif_tallies_search = [{i: 0 for i in range(1, 9)} for i in range(8)]\n",
    "    motif_tallies_edit = [{i: 0 for i in range(1, 9)} for i in range(8)]\n",
    "    search_accs, caller_accs, edit_accs = [], [], []\n",
    "    for i, j, k in zip(search_prediction, caller_prediction, edit_prediction):  # for each prediction\n",
    "        cycle_num = 0\n",
    "        for search_cycle, caller_cycle, edit_cycle in zip(i, j, k):  # loop over cycles and update tallies\n",
    "            for motif in search_cycle:\n",
    "                motif_tallies_search[cycle_num][motif] += 1\n",
    "            for motif in caller_cycle:\n",
    "                motif_tallies_caller[cycle_num][motif] += 1\n",
    "            for motif in edit_cycle:\n",
    "                motif_tallies_edit[cycle_num][motif] += 1\n",
    "            cycle_num += 1\n",
    "\n",
    "        #  Get caller and search predictions\n",
    "        caller_prediction_ = get_top_4_motifs(motif_tallies_caller)\n",
    "        search_prediction_ = get_top_4_motifs(motif_tallies_search)\n",
    "        edit_prediction_ = get_top_4_motifs(motif_tallies_edit)\n",
    "        \n",
    "        n_reads += 1\n",
    "\n",
    "        #print(payload)\n",
    "        #payload = eval(payload)  # comment out for other datasets\n",
    "        #  Evaluate predictions\n",
    "        search_acc = evaluate_prediction(search_prediction_, payload)[0]/32\n",
    "        caller_acc  = evaluate_prediction(caller_prediction_, payload)[0]/32\n",
    "        edit_acc = evaluate_prediction(edit_prediction_, payload)[0]/32\n",
    "        \n",
    "\n",
    "        search_accs.append(search_acc)\n",
    "        caller_accs.append(caller_acc)\n",
    "        edit_accs.append(edit_acc)\n",
    "        \n",
    "    \n",
    "    search_accs_arr.append(search_accs)\n",
    "    caller_accs_arr.append(caller_accs)\n",
    "    edit_accs_arr.append(edit_accs)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa0bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i[-1] for i in edit_accs_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49fe9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_search = []\n",
    "avg_caller = []\n",
    "avg_edit = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    search_sum = 0\n",
    "    search_samples = 0\n",
    "    for k in search_accs_arr:\n",
    "        if i < len(k):\n",
    "            search_sum += k[i]\n",
    "            search_samples += 1\n",
    "    \n",
    "    caller_sum = 0\n",
    "    caller_samples = 0\n",
    "    for k in caller_accs_arr:\n",
    "        if i < len(k):\n",
    "            caller_sum += k[i]\n",
    "            caller_samples += 1\n",
    "\n",
    "    edit_sum = 0\n",
    "    edit_samples = 0\n",
    "    for k in edit_accs_arr:\n",
    "        if i < len(k):\n",
    "            edit_sum += k[i]\n",
    "            edit_samples += 1\n",
    "\n",
    "    avg_search.append(search_sum / search_samples)\n",
    "    #avg_caller.append(caller_sum / caller_samples)\n",
    "    #avg_edit.append(edit_sum / edit_samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(avg_search, label='zero-error search')\n",
    "plt.plot(avg_caller, label='motif caller')\n",
    "plt.plot(avg_edit, label='edit search')\n",
    "plt.grid()\n",
    "plt.yticks(np.arange(0, 1.01, 0.05))\n",
    "#plt.xticks(np.arange(0, 200, 2))\n",
    "plt.xlim(0, 70)\n",
    "plt.xlabel(\"Number of reads\")\n",
    "plt.ylabel(\"Recovery percentage\")\n",
    "plt.title(\"Convergence of motif-inferring methods\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769f05f",
   "metadata": {},
   "source": [
    "### Evaluating zero-error search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b964a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sort_library_motif_transcript(library_prediction):\n",
    "    \"\"\"Sorts library motif transcripts while fixing for typos, by looking at the payloads to get the best orientation matches\"\"\"\n",
    "\n",
    "    sorted_prediction = [[] for i in range(10)]\n",
    "\n",
    "    split_library_prediction = library_prediction.split('|')\n",
    "\n",
    "    #print(split_library_prediction)\n",
    "    for i in split_library_prediction:\n",
    "\n",
    "        if len(i) < 8:\n",
    "            continue\n",
    "        # searching for the 10\n",
    "        motif_found = int(i[-1])\n",
    "        cycle_address = None  # starts from 1 there and from 0 here\n",
    "        if i[-4] == '1':\n",
    "            if i[-3] == '0':\n",
    "                cycle_address = 10\n",
    "                sorted_prediction[cycle_address - 1].append(motif_found)\n",
    "        elif i[-4] == '9':\n",
    "            continue\n",
    "        else:\n",
    "            cycle_address = int(i[-3])\n",
    "            sorted_prediction[cycle_address - 1].append(motif_found)\n",
    "\n",
    "    return sorted_prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b793f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_df = pd.read_pickle(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\sequencing_runs\\01-13\\01-13-test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50124f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_motifs = ms_df['library_motif'].tolist()\n",
    "read_id_arr = ms_df['read_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_seq_arr = []\n",
    "read_ids_arr = []\n",
    "\n",
    "for i, j in zip(lib_motifs, read_id_arr):\n",
    "    try:\n",
    "        motif_seq = sort_library_motif_transcript(i)\n",
    "        motif_seq_arr.append(motif_seq)\n",
    "        read_ids_arr.append(j)\n",
    "    except:\n",
    "        print(f\"Exception at {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3772a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(ms_df, pd.DataFrame({\n",
    "    \"read_id\": read_ids_arr,\n",
    "    \"motif_seq\": motif_seq_arr\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e384eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff5300",
   "metadata": {},
   "source": [
    "### Checking average quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f801dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\fastq\\EIC01-01-1280\\FASTQ(pass_fail_logs)\\fail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0d5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2492cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "avg_qs = []\n",
    "for file in tqdm(os.listdir(basepath)):\n",
    "    for record in SeqIO.parse(os.path.join(basepath, file), \"fastq\"):\n",
    "        score=record.letter_annotations[\"phred_quality\"]\n",
    "        avg_qs.append(np.mean(score))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(avg_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589eac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_sizes = []\n",
    "fail_sizes = []\n",
    "\n",
    "for file in tqdm(os.listdir(basepath)):\n",
    "    pass_sizes.append(os.path.getsize(os.path.join(basepath, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cccc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fail_sizes = []\n",
    "for file in tqdm(os.listdir(basepath)[:544]):\n",
    "    fail_sizes.append(os.path.getsize(os.path.join(basepath, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pass_sizes) / (np.mean(pass_sizes) + np.mean(fail_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71785220",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(qualities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "motif_search_coded = pd.read_csv(r\"C:\\Users\\Parv\\Doc\\HelixWorks\\Basecalling\\code\\motifcaller\\data\\empirical\\motif_search_barcoded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ca540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
